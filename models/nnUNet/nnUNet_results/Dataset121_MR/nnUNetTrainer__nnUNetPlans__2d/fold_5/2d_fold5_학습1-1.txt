
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': [448, 512], 'median_image_size_in_voxels': [392.0, 496.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset121_MR', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 392, 496], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 91.21957397460938, 'median': 78.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 63.28199005126953}}} 
 
2023-11-29 14:08:43.951680: unpacking dataset... 
2023-11-29 14:08:46.600860: unpacking done... 
2023-11-29 14:08:46.605860: do_dummy_2d_data_aug: False 
2023-11-29 14:08:46.622401: Creating new 5-fold cross-validation split... 
2023-11-29 14:08:46.633908: Desired fold for training: 5 
2023-11-29 14:08:46.639417: INFO: You requested fold 5 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split! 
2023-11-29 14:08:46.647936: This random 80:20 split has 776 training and 194 validation cases. 
2023-11-29 14:08:46.724950: Unable to plot network architecture: 
2023-11-29 14:08:46.730460: No module named 'IPython' 
2023-11-29 14:08:46.839420:  
2023-11-29 14:08:46.845421: Epoch 0 
2023-11-29 14:08:46.850973: Current learning rate: 0.01 
2023-11-29 14:11:09.963461: train_loss -0.4968 
2023-11-29 14:11:09.972978: val_loss -0.8545 
2023-11-29 14:11:09.980498: Pseudo dice [0.9621, 0.963, 0.9166] 
2023-11-29 14:11:09.986528: Epoch time: 143.2 s 
2023-11-29 14:11:09.992040: Yayy! New best EMA pseudo Dice: 0.9473 
2023-11-29 14:11:11.238545:  
2023-11-29 14:11:11.244548: Epoch 1 
2023-11-29 14:11:11.250057: Current learning rate: 0.00999 
2023-11-29 14:13:04.803429: train_loss -0.8736 
2023-11-29 14:13:04.811942: val_loss -0.8946 
2023-11-29 14:13:04.818453: Pseudo dice [0.9706, 0.9724, 0.934] 
2023-11-29 14:13:04.826075: Epoch time: 113.57 s 
2023-11-29 14:13:04.831962: Yayy! New best EMA pseudo Dice: 0.9484 
2023-11-29 14:13:06.311008:  
2023-11-29 14:13:06.317517: Epoch 2 
2023-11-29 14:13:06.322518: Current learning rate: 0.00998 
2023-11-29 14:15:52.586985: train_loss -0.8998 
2023-11-29 14:15:52.602644: val_loss -0.9106 
2023-11-29 14:15:52.608154: Pseudo dice [0.9736, 0.977, 0.9418] 
2023-11-29 14:15:52.615663: Epoch time: 166.28 s 
2023-11-29 14:15:52.622667: Yayy! New best EMA pseudo Dice: 0.95 
2023-11-29 14:15:54.102622:  
2023-11-29 14:15:54.107127: Epoch 3 
2023-11-29 14:15:54.111126: Current learning rate: 0.00997 
2023-11-29 14:17:16.205637: train_loss -0.9112 
2023-11-29 14:17:16.212644: val_loss -0.9173 
2023-11-29 14:17:16.220154: Pseudo dice [0.9764, 0.9787, 0.9454] 
2023-11-29 14:17:16.228200: Epoch time: 82.11 s 
2023-11-29 14:17:16.236285: Yayy! New best EMA pseudo Dice: 0.9517 
2023-11-29 14:17:17.669424:  
2023-11-29 14:17:17.673769: Epoch 4 
2023-11-29 14:17:17.679327: Current learning rate: 0.00996 
2023-11-29 14:18:40.294104: train_loss -0.9184 
2023-11-29 14:18:40.301620: val_loss -0.9213 
2023-11-29 14:18:40.307133: Pseudo dice [0.9776, 0.9791, 0.9478] 
2023-11-29 14:18:40.314136: Epoch time: 82.63 s 
2023-11-29 14:18:40.319654: Yayy! New best EMA pseudo Dice: 0.9533 
2023-11-29 14:18:41.830678:  
2023-11-29 14:18:41.836227: Epoch 5 
2023-11-29 14:18:41.840898: Current learning rate: 0.00995 
2023-11-29 14:20:03.152558: train_loss -0.9201 
2023-11-29 14:20:03.160559: val_loss -0.9228 
2023-11-29 14:20:03.166558: Pseudo dice [0.9777, 0.9796, 0.9485] 
2023-11-29 14:20:03.173570: Epoch time: 81.32 s 
2023-11-29 14:20:03.180560: Yayy! New best EMA pseudo Dice: 0.9549 
2023-11-29 14:20:04.523571:  
2023-11-29 14:20:04.529113: Epoch 6 
2023-11-29 14:20:04.533880: Current learning rate: 0.00995 
2023-11-29 14:21:30.249562: train_loss -0.9173 
2023-11-29 14:21:30.259075: val_loss -0.9228 
2023-11-29 14:21:30.266588: Pseudo dice [0.9784, 0.9792, 0.9484] 
2023-11-29 14:21:30.273594: Epoch time: 85.73 s 
2023-11-29 14:21:30.281107: Yayy! New best EMA pseudo Dice: 0.9562 
2023-11-29 14:21:31.967387:  
2023-11-29 14:21:31.973388: Epoch 7 
2023-11-29 14:21:31.980896: Current learning rate: 0.00994 
2023-11-29 14:23:01.855036: train_loss -0.9226 
2023-11-29 14:23:01.863549: val_loss -0.9253 
2023-11-29 14:23:01.871064: Pseudo dice [0.9777, 0.9806, 0.9499] 
2023-11-29 14:23:01.877576: Epoch time: 89.89 s 
2023-11-29 14:23:01.883575: Yayy! New best EMA pseudo Dice: 0.9576 
2023-11-29 14:23:03.305563:  
2023-11-29 14:23:03.310231: Epoch 8 
2023-11-29 14:23:03.315232: Current learning rate: 0.00993 
2023-11-29 14:24:43.406039: train_loss -0.927 
2023-11-29 14:24:43.413042: val_loss -0.9272 
2023-11-29 14:24:43.420554: Pseudo dice [0.9793, 0.9807, 0.9502] 
2023-11-29 14:24:43.428065: Epoch time: 100.1 s 
2023-11-29 14:24:43.435571: Yayy! New best EMA pseudo Dice: 0.9588 
2023-11-29 14:24:44.849890:  
2023-11-29 14:24:44.855397: Epoch 9 
2023-11-29 14:24:44.860408: Current learning rate: 0.00992 
2023-11-29 14:26:21.764977: train_loss -0.9289 
2023-11-29 14:26:21.771984: val_loss -0.928 
2023-11-29 14:26:21.779496: Pseudo dice [0.9794, 0.9807, 0.9506] 
2023-11-29 14:26:21.786010: Epoch time: 96.92 s 
2023-11-29 14:26:21.792009: Yayy! New best EMA pseudo Dice: 0.9599 
2023-11-29 14:26:23.245349:  
2023-11-29 14:26:23.250932: Epoch 10 
2023-11-29 14:26:23.256569: Current learning rate: 0.00991 
2023-11-29 14:27:45.450442: train_loss -0.9286 
2023-11-29 14:27:45.456954: val_loss -0.928 
2023-11-29 14:27:45.462953: Pseudo dice [0.9791, 0.981, 0.9508] 
2023-11-29 14:27:45.471463: Epoch time: 82.21 s 
2023-11-29 14:27:45.478974: Yayy! New best EMA pseudo Dice: 0.961 
2023-11-29 14:27:46.869699:  
2023-11-29 14:27:46.875205: Epoch 11 
2023-11-29 14:27:46.879209: Current learning rate: 0.0099 
2023-11-29 14:29:08.487582: train_loss -0.9298 
2023-11-29 14:29:08.495609: val_loss -0.9295 
2023-11-29 14:29:08.500605: Pseudo dice [0.9801, 0.9816, 0.9516] 
2023-11-29 14:29:08.507117: Epoch time: 81.62 s 
2023-11-29 14:29:08.512116: Yayy! New best EMA pseudo Dice: 0.962 
2023-11-29 14:29:09.893245:  
2023-11-29 14:29:09.897787: Epoch 12 
2023-11-29 14:29:09.902701: Current learning rate: 0.00989 
2023-11-29 14:30:55.320843: train_loss -0.9302 
2023-11-29 14:30:55.328860: val_loss -0.9325 
2023-11-29 14:30:55.337384: Pseudo dice [0.9806, 0.9821, 0.9536] 
2023-11-29 14:30:55.343882: Epoch time: 105.43 s 
2023-11-29 14:30:55.351895: Yayy! New best EMA pseudo Dice: 0.963 
2023-11-29 14:30:56.739534:  
2023-11-29 14:30:56.744712: Epoch 13 
2023-11-29 14:30:56.751346: Current learning rate: 0.00988 
2023-11-29 14:32:42.365817: train_loss -0.929 
2023-11-29 14:32:42.375326: val_loss -0.9297 
2023-11-29 14:32:42.383838: Pseudo dice [0.9792, 0.9816, 0.9521] 
2023-11-29 14:32:42.392849: Epoch time: 105.63 s 
2023-11-29 14:32:42.402066: Yayy! New best EMA pseudo Dice: 0.9638 
2023-11-29 14:32:44.305685:  
2023-11-29 14:32:44.312685: Epoch 14 
2023-11-29 14:32:44.318208: Current learning rate: 0.00987 
2023-11-29 14:34:18.685425: train_loss -0.9314 
2023-11-29 14:34:18.694453: val_loss -0.9306 
2023-11-29 14:34:18.702452: Pseudo dice [0.9805, 0.9811, 0.952] 
2023-11-29 14:34:18.707963: Epoch time: 94.38 s 
2023-11-29 14:34:18.714476: Yayy! New best EMA pseudo Dice: 0.9645 
2023-11-29 14:34:20.262361:  
2023-11-29 14:34:20.267678: Epoch 15 
2023-11-29 14:34:20.272460: Current learning rate: 0.00986 
2023-11-29 14:35:43.552869: train_loss -0.9339 
2023-11-29 14:35:43.560874: val_loss -0.9311 
2023-11-29 14:35:43.568387: Pseudo dice [0.9805, 0.9816, 0.9529] 
2023-11-29 14:35:43.575415: Epoch time: 83.29 s 
2023-11-29 14:35:43.582917: Yayy! New best EMA pseudo Dice: 0.9653 
2023-11-29 14:35:45.006437:  
2023-11-29 14:35:45.011438: Epoch 16 
2023-11-29 14:35:45.015945: Current learning rate: 0.00986 
2023-11-29 14:37:16.199372: train_loss -0.9336 
2023-11-29 14:37:16.205887: val_loss -0.9323 
2023-11-29 14:37:16.213392: Pseudo dice [0.9811, 0.9819, 0.9532] 
2023-11-29 14:37:16.219401: Epoch time: 91.19 s 
2023-11-29 14:37:16.224914: Yayy! New best EMA pseudo Dice: 0.9659 
2023-11-29 14:37:17.670653:  
2023-11-29 14:37:17.676242: Epoch 17 
2023-11-29 14:37:17.680203: Current learning rate: 0.00985 
2023-11-29 14:38:39.456024: train_loss -0.9334 
2023-11-29 14:38:39.462528: val_loss -0.9325 
2023-11-29 14:38:39.470540: Pseudo dice [0.9806, 0.982, 0.9534] 
2023-11-29 14:38:39.476052: Epoch time: 81.79 s 
2023-11-29 14:38:39.481054: Yayy! New best EMA pseudo Dice: 0.9665 
2023-11-29 14:38:40.895280:  
2023-11-29 14:38:40.901279: Epoch 18 
2023-11-29 14:38:40.905788: Current learning rate: 0.00984 
2023-11-29 14:40:13.590722: train_loss -0.936 
2023-11-29 14:40:13.599748: val_loss -0.9339 
2023-11-29 14:40:13.605814: Pseudo dice [0.9813, 0.9825, 0.9541] 
2023-11-29 14:40:13.613326: Epoch time: 92.7 s 
2023-11-29 14:40:13.621326: Yayy! New best EMA pseudo Dice: 0.9672 
2023-11-29 14:40:15.081344:  
2023-11-29 14:40:15.086937: Epoch 19 
2023-11-29 14:40:15.092448: Current learning rate: 0.00983 
2023-11-29 14:41:45.110372: train_loss -0.9372 
2023-11-29 14:41:45.119887: val_loss -0.9345 
2023-11-29 14:41:45.127402: Pseudo dice [0.9812, 0.9822, 0.9541] 
2023-11-29 14:41:45.133917: Epoch time: 90.03 s 
2023-11-29 14:41:45.141939: Yayy! New best EMA pseudo Dice: 0.9677 
2023-11-29 14:41:46.694388:  
2023-11-29 14:41:46.699426: Epoch 20 
2023-11-29 14:41:46.704977: Current learning rate: 0.00982 
2023-11-29 14:43:05.763724: train_loss -0.9382 
2023-11-29 14:43:05.772236: val_loss -0.9344 
2023-11-29 14:43:05.779250: Pseudo dice [0.9818, 0.9822, 0.9545] 
2023-11-29 14:43:05.786772: Epoch time: 79.07 s 
2023-11-29 14:43:05.796287: Yayy! New best EMA pseudo Dice: 0.9682 
2023-11-29 14:43:07.266238:  
2023-11-29 14:43:07.271951: Epoch 21 
2023-11-29 14:43:07.276944: Current learning rate: 0.00981 
2023-11-29 14:44:29.906583: train_loss -0.9386 
2023-11-29 14:44:29.915097: val_loss -0.9313 
2023-11-29 14:44:29.921601: Pseudo dice [0.9813, 0.9818, 0.9522] 
2023-11-29 14:44:29.928612: Epoch time: 82.64 s 
2023-11-29 14:44:29.936124: Yayy! New best EMA pseudo Dice: 0.9686 
2023-11-29 14:44:31.274769:  
2023-11-29 14:44:31.280769: Epoch 22 
2023-11-29 14:44:31.285343: Current learning rate: 0.0098 
2023-11-29 14:45:53.023950: train_loss -0.9391 
2023-11-29 14:45:53.031454: val_loss -0.9354 
2023-11-29 14:45:53.038968: Pseudo dice [0.9819, 0.9828, 0.9548] 
2023-11-29 14:45:53.044479: Epoch time: 81.75 s 
2023-11-29 14:45:53.051983: Yayy! New best EMA pseudo Dice: 0.969 
2023-11-29 14:45:54.377992:  
2023-11-29 14:45:54.383504: Epoch 23 
2023-11-29 14:45:54.388537: Current learning rate: 0.00979 
2023-11-29 14:47:14.745974: train_loss -0.9394 
2023-11-29 14:47:14.753174: val_loss -0.9354 
2023-11-29 14:47:14.759171: Pseudo dice [0.9818, 0.983, 0.955] 
2023-11-29 14:47:14.764683: Epoch time: 80.37 s 
2023-11-29 14:47:14.771189: Yayy! New best EMA pseudo Dice: 0.9694 
2023-11-29 14:47:16.118865:  
2023-11-29 14:47:16.124019: Epoch 24 
2023-11-29 14:47:16.129019: Current learning rate: 0.00978 
2023-11-29 14:48:34.073947: train_loss -0.938 
2023-11-29 14:48:34.082457: val_loss -0.9331 
2023-11-29 14:48:34.089458: Pseudo dice [0.9808, 0.9821, 0.9542] 
2023-11-29 14:48:34.096970: Epoch time: 77.96 s 
2023-11-29 14:48:34.103482: Yayy! New best EMA pseudo Dice: 0.9697 
2023-11-29 14:48:35.453576:  
2023-11-29 14:48:35.458576: Epoch 25 
2023-11-29 14:48:35.464158: Current learning rate: 0.00977 
2023-11-29 14:49:55.732968: train_loss -0.9382 
2023-11-29 14:49:55.732968: val_loss -0.9331 
2023-11-29 14:49:55.740480: Pseudo dice [0.9816, 0.9822, 0.954] 
2023-11-29 14:49:55.747486: Epoch time: 80.28 s 
2023-11-29 14:49:55.753522: Yayy! New best EMA pseudo Dice: 0.97 
2023-11-29 14:49:57.100817:  
2023-11-29 14:49:57.106735: Epoch 26 
2023-11-29 14:49:57.111411: Current learning rate: 0.00977 
2023-11-29 14:51:16.445221: train_loss -0.9397 
2023-11-29 14:51:16.454744: val_loss -0.9356 
2023-11-29 14:51:16.463263: Pseudo dice [0.9816, 0.983, 0.9552] 
2023-11-29 14:51:16.469264: Epoch time: 79.35 s 
2023-11-29 14:51:16.478781: Yayy! New best EMA pseudo Dice: 0.9703 
2023-11-29 14:51:17.821120:  
2023-11-29 14:51:17.827164: Epoch 27 
2023-11-29 14:51:17.831801: Current learning rate: 0.00976 
2023-11-29 14:52:37.718626: train_loss -0.9407 
2023-11-29 14:52:37.727138: val_loss -0.9361 
2023-11-29 14:52:37.734650: Pseudo dice [0.9816, 0.983, 0.9555] 
2023-11-29 14:52:37.742171: Epoch time: 79.9 s 
2023-11-29 14:52:37.750160: Yayy! New best EMA pseudo Dice: 0.9706 
2023-11-29 14:52:39.193593:  
2023-11-29 14:52:39.198623: Epoch 28 
2023-11-29 14:52:39.203214: Current learning rate: 0.00975 
2023-11-29 14:53:58.337140: train_loss -0.9402 
2023-11-29 14:53:58.344653: val_loss -0.9324 
2023-11-29 14:53:58.351163: Pseudo dice [0.9815, 0.9821, 0.9537] 
2023-11-29 14:53:58.358162: Epoch time: 79.15 s 
2023-11-29 14:53:58.365674: Yayy! New best EMA pseudo Dice: 0.9708 
2023-11-29 14:53:59.700359:  
2023-11-29 14:53:59.704962: Epoch 29 
2023-11-29 14:53:59.710423: Current learning rate: 0.00974 
2023-11-29 14:55:18.982094: train_loss -0.9396 
2023-11-29 14:55:18.983093: val_loss -0.9357 
2023-11-29 14:55:18.991098: Pseudo dice [0.9821, 0.9828, 0.9552] 
2023-11-29 14:55:18.999101: Epoch time: 79.28 s 
2023-11-29 14:55:19.006612: Yayy! New best EMA pseudo Dice: 0.9711 
2023-11-29 14:55:20.416718:  
2023-11-29 14:55:20.417474: Epoch 30 
2023-11-29 14:55:20.422551: Current learning rate: 0.00973 
2023-11-29 14:56:40.662367: train_loss -0.9416 
2023-11-29 14:56:40.663367: val_loss -0.9362 
2023-11-29 14:56:40.671367: Pseudo dice [0.9818, 0.9829, 0.9556] 
2023-11-29 14:56:40.681368: Epoch time: 80.25 s 
2023-11-29 14:56:40.691372: Yayy! New best EMA pseudo Dice: 0.9713 
2023-11-29 14:56:42.328688:  
2023-11-29 14:56:42.328688: Epoch 31 
2023-11-29 14:56:42.335879: Current learning rate: 0.00972 
2023-11-29 14:58:05.094206: train_loss -0.9424 
2023-11-29 14:58:05.095105: val_loss -0.9354 
2023-11-29 14:58:05.103106: Pseudo dice [0.9814, 0.9824, 0.9553] 
2023-11-29 14:58:05.110616: Epoch time: 82.77 s 
2023-11-29 14:58:05.118133: Yayy! New best EMA pseudo Dice: 0.9715 
2023-11-29 14:58:06.551580:  
2023-11-29 14:58:06.551580: Epoch 32 
2023-11-29 14:58:06.558100: Current learning rate: 0.00971 
2023-11-29 14:59:26.751783: train_loss -0.9429 
2023-11-29 14:59:26.752784: val_loss -0.937 
2023-11-29 14:59:26.760295: Pseudo dice [0.9822, 0.9832, 0.9559] 
2023-11-29 14:59:26.767806: Epoch time: 80.2 s 
2023-11-29 14:59:26.775316: Yayy! New best EMA pseudo Dice: 0.9717 
2023-11-29 14:59:28.151579:  
2023-11-29 14:59:28.151579: Epoch 33 
2023-11-29 14:59:28.157166: Current learning rate: 0.0097 
2023-11-29 15:00:46.750725: train_loss -0.9424 
2023-11-29 15:00:46.751727: val_loss -0.9366 
2023-11-29 15:00:46.757858: Pseudo dice [0.9816, 0.9834, 0.9561] 
2023-11-29 15:00:46.763860: Epoch time: 78.6 s 
2023-11-29 15:00:46.770940: Yayy! New best EMA pseudo Dice: 0.9719 
2023-11-29 15:00:48.128010:  
2023-11-29 15:00:48.133004: Epoch 34 
2023-11-29 15:00:48.137737: Current learning rate: 0.00969 
2023-11-29 15:02:07.014471: train_loss -0.9433 
2023-11-29 15:02:07.044550: val_loss -0.9356 
2023-11-29 15:02:07.053556: Pseudo dice [0.9824, 0.9832, 0.9557] 
2023-11-29 15:02:07.064582: Epoch time: 78.89 s 
2023-11-29 15:02:07.071586: Yayy! New best EMA pseudo Dice: 0.9721 
2023-11-29 15:02:08.461962:  
2023-11-29 15:02:08.468383: Epoch 35 
2023-11-29 15:02:08.472390: Current learning rate: 0.00968 
2023-11-29 15:03:28.118304: train_loss -0.9421 
2023-11-29 15:03:28.127389: val_loss -0.9337 
2023-11-29 15:03:28.136503: Pseudo dice [0.9813, 0.9823, 0.954] 
2023-11-29 15:03:28.145851: Epoch time: 79.66 s 
2023-11-29 15:03:28.154360: Yayy! New best EMA pseudo Dice: 0.9721 
2023-11-29 15:03:29.683411:  
2023-11-29 15:03:29.689044: Epoch 36 
2023-11-29 15:03:29.693667: Current learning rate: 0.00968 
2023-11-29 15:04:48.108801: train_loss -0.9418 
2023-11-29 15:04:48.117313: val_loss -0.9371 
2023-11-29 15:04:48.123317: Pseudo dice [0.9818, 0.9832, 0.956] 
2023-11-29 15:04:48.129445: Epoch time: 78.43 s 
2023-11-29 15:04:48.135960: Yayy! New best EMA pseudo Dice: 0.9723 
2023-11-29 15:04:49.517942:  
2023-11-29 15:04:49.522942: Epoch 37 
2023-11-29 15:04:49.528289: Current learning rate: 0.00967 
2023-11-29 15:06:07.596006: train_loss -0.9435 
2023-11-29 15:06:07.604523: val_loss -0.9365 
2023-11-29 15:06:07.610522: Pseudo dice [0.982, 0.9828, 0.9555] 
2023-11-29 15:06:07.619040: Epoch time: 78.08 s 
2023-11-29 15:06:07.627554: Yayy! New best EMA pseudo Dice: 0.9724 
2023-11-29 15:06:09.062756:  
2023-11-29 15:06:09.068351: Epoch 38 
2023-11-29 15:06:09.072987: Current learning rate: 0.00966 
2023-11-29 15:07:29.130249: train_loss -0.9448 
2023-11-29 15:07:29.136759: val_loss -0.936 
2023-11-29 15:07:29.143261: Pseudo dice [0.9819, 0.983, 0.9558] 
2023-11-29 15:07:29.150272: Epoch time: 80.07 s 
2023-11-29 15:07:29.166848: Yayy! New best EMA pseudo Dice: 0.9725 
2023-11-29 15:07:30.541718:  
2023-11-29 15:07:30.546293: Epoch 39 
2023-11-29 15:07:30.551497: Current learning rate: 0.00965 
2023-11-29 15:08:48.948748: train_loss -0.9444 
2023-11-29 15:08:48.956264: val_loss -0.9359 
2023-11-29 15:08:48.964775: Pseudo dice [0.982, 0.9827, 0.956] 
2023-11-29 15:08:48.972370: Epoch time: 78.41 s 
2023-11-29 15:08:48.980283: Yayy! New best EMA pseudo Dice: 0.9726 
2023-11-29 15:08:50.389082:  
2023-11-29 15:08:50.393937: Epoch 40 
2023-11-29 15:08:50.398945: Current learning rate: 0.00964 
2023-11-29 15:10:09.652433: train_loss -0.9432 
2023-11-29 15:10:09.653335: val_loss -0.9372 
2023-11-29 15:10:09.660340: Pseudo dice [0.982, 0.9834, 0.9564] 
2023-11-29 15:10:09.669405: Epoch time: 79.27 s 
2023-11-29 15:10:09.676919: Yayy! New best EMA pseudo Dice: 0.9728 
2023-11-29 15:10:11.236857:  
2023-11-29 15:10:11.242367: Epoch 41 
2023-11-29 15:10:11.247422: Current learning rate: 0.00963 
2023-11-29 15:11:30.626971: train_loss -0.944 
2023-11-29 15:11:30.634971: val_loss -0.9348 
2023-11-29 15:11:30.641974: Pseudo dice [0.9819, 0.9827, 0.9552] 
2023-11-29 15:11:30.648972: Epoch time: 79.39 s 
2023-11-29 15:11:30.654978: Yayy! New best EMA pseudo Dice: 0.9728 
2023-11-29 15:11:31.969354:  
2023-11-29 15:11:31.974674: Epoch 42 
2023-11-29 15:11:31.979766: Current learning rate: 0.00962 
2023-11-29 15:12:49.209134: train_loss -0.9444 
2023-11-29 15:12:49.216641: val_loss -0.9359 
2023-11-29 15:12:49.222641: Pseudo dice [0.9823, 0.9832, 0.956] 
2023-11-29 15:12:49.229641: Epoch time: 77.24 s 
2023-11-29 15:12:49.235641: Yayy! New best EMA pseudo Dice: 0.9729 
2023-11-29 15:12:50.562305:  
2023-11-29 15:12:50.567272: Epoch 43 
2023-11-29 15:12:50.572109: Current learning rate: 0.00961 
2023-11-29 15:14:09.031497: train_loss -0.9452 
2023-11-29 15:14:09.038498: val_loss -0.9364 
2023-11-29 15:14:09.046007: Pseudo dice [0.9821, 0.9831, 0.9557] 
2023-11-29 15:14:09.053008: Epoch time: 78.47 s 
2023-11-29 15:14:09.061007: Yayy! New best EMA pseudo Dice: 0.973 
2023-11-29 15:14:10.436052:  
2023-11-29 15:14:10.440570: Epoch 44 
2023-11-29 15:14:10.447082: Current learning rate: 0.0096 
2023-11-29 15:15:31.674443: train_loss -0.946 
2023-11-29 15:15:31.681960: val_loss -0.936 
2023-11-29 15:15:31.688465: Pseudo dice [0.9825, 0.9831, 0.9555] 
2023-11-29 15:15:31.694476: Epoch time: 81.24 s 
2023-11-29 15:15:31.702991: Yayy! New best EMA pseudo Dice: 0.9731 
2023-11-29 15:15:33.030296:  
2023-11-29 15:15:33.035406: Epoch 45 
2023-11-29 15:15:33.040074: Current learning rate: 0.00959 
2023-11-29 15:16:53.839991: train_loss -0.9471 
2023-11-29 15:16:53.846993: val_loss -0.9377 
2023-11-29 15:16:53.853511: Pseudo dice [0.9822, 0.9834, 0.9564] 
2023-11-29 15:16:53.861021: Epoch time: 80.81 s 
2023-11-29 15:16:53.869525: Yayy! New best EMA pseudo Dice: 0.9731 
2023-11-29 15:16:55.315649:  
2023-11-29 15:16:55.321158: Epoch 46 
2023-11-29 15:16:55.325943: Current learning rate: 0.00959 
2023-11-29 15:18:15.731881: train_loss -0.9463 
2023-11-29 15:18:15.738388: val_loss -0.9364 
2023-11-29 15:18:15.744393: Pseudo dice [0.9819, 0.9831, 0.956] 
2023-11-29 15:18:15.751910: Epoch time: 80.42 s 
2023-11-29 15:18:15.760417: Yayy! New best EMA pseudo Dice: 0.9732 
2023-11-29 15:18:17.081803:  
2023-11-29 15:18:17.087766: Epoch 47 
2023-11-29 15:18:17.092165: Current learning rate: 0.00958 
2023-11-29 15:19:37.265871: train_loss -0.9467 
2023-11-29 15:19:37.273872: val_loss -0.938 
2023-11-29 15:19:37.280874: Pseudo dice [0.9823, 0.9836, 0.9572] 
2023-11-29 15:19:37.288870: Epoch time: 80.19 s 
2023-11-29 15:19:37.296872: Yayy! New best EMA pseudo Dice: 0.9733 
2023-11-29 15:19:38.612326:  
2023-11-29 15:19:38.618572: Epoch 48 
2023-11-29 15:19:38.623089: Current learning rate: 0.00957 
2023-11-29 15:20:55.841437: train_loss -0.948 
2023-11-29 15:20:55.849441: val_loss -0.9363 
2023-11-29 15:20:55.856441: Pseudo dice [0.982, 0.9832, 0.956] 
2023-11-29 15:20:55.863952: Epoch time: 77.23 s 
2023-11-29 15:20:55.869953: Yayy! New best EMA pseudo Dice: 0.9734 
2023-11-29 15:20:57.193652:  
2023-11-29 15:20:57.199697: Epoch 49 
2023-11-29 15:20:57.204422: Current learning rate: 0.00956 
2023-11-29 15:22:16.952579: train_loss -0.9476 
2023-11-29 15:22:16.959628: val_loss -0.9345 
2023-11-29 15:22:16.966627: Pseudo dice [0.982, 0.9826, 0.9553] 
2023-11-29 15:22:16.975627: Epoch time: 79.76 s 
2023-11-29 15:22:18.314425:  
2023-11-29 15:22:18.320755: Epoch 50 
2023-11-29 15:22:18.325512: Current learning rate: 0.00955 
2023-11-29 15:23:38.251476: train_loss -0.9478 
2023-11-29 15:23:38.260475: val_loss -0.9378 
2023-11-29 15:23:38.268475: Pseudo dice [0.9822, 0.9832, 0.9563] 
2023-11-29 15:23:38.276474: Epoch time: 79.94 s 
2023-11-29 15:23:38.284475: Yayy! New best EMA pseudo Dice: 0.9734 
2023-11-29 15:23:39.750800:  
2023-11-29 15:23:39.756802: Epoch 51 
2023-11-29 15:23:39.761801: Current learning rate: 0.00954 
2023-11-29 15:24:59.987187: train_loss -0.947 
2023-11-29 15:24:59.993697: val_loss -0.9356 
2023-11-29 15:25:00.000207: Pseudo dice [0.9824, 0.9825, 0.9549] 
2023-11-29 15:25:00.008588: Epoch time: 80.24 s 
2023-11-29 15:25:01.087597:  
2023-11-29 15:25:01.093117: Epoch 52 
2023-11-29 15:25:01.098620: Current learning rate: 0.00953 
2023-11-29 15:26:20.850013: train_loss -0.9485 
2023-11-29 15:26:20.859011: val_loss -0.9352 
2023-11-29 15:26:20.867012: Pseudo dice [0.9822, 0.9828, 0.9546] 
2023-11-29 15:26:20.874012: Epoch time: 79.76 s 
2023-11-29 15:26:21.953549:  
2023-11-29 15:26:21.958993: Epoch 53 
2023-11-29 15:26:21.964761: Current learning rate: 0.00952 
2023-11-29 15:27:40.435505: train_loss -0.9492 
2023-11-29 15:27:40.443504: val_loss -0.9371 
2023-11-29 15:27:40.452014: Pseudo dice [0.9825, 0.9833, 0.9568] 
2023-11-29 15:27:40.459013: Epoch time: 78.48 s 
2023-11-29 15:27:40.466012: Yayy! New best EMA pseudo Dice: 0.9735 
2023-11-29 15:27:41.795138:  
2023-11-29 15:27:41.800305: Epoch 54 
2023-11-29 15:27:41.805305: Current learning rate: 0.00951 
2023-11-29 15:29:02.155951: train_loss -0.9494 
2023-11-29 15:29:02.163952: val_loss -0.9371 
2023-11-29 15:29:02.172956: Pseudo dice [0.9823, 0.9836, 0.9563] 
2023-11-29 15:29:02.179961: Epoch time: 80.36 s 
2023-11-29 15:29:02.189363: Yayy! New best EMA pseudo Dice: 0.9735 
2023-11-29 15:29:03.574338:  
2023-11-29 15:29:03.580336: Epoch 55 
2023-11-29 15:29:03.588852: Current learning rate: 0.0095 
2023-11-29 15:30:23.671110: train_loss -0.9493 
2023-11-29 15:30:23.681115: val_loss -0.9349 
2023-11-29 15:30:23.689111: Pseudo dice [0.9819, 0.9829, 0.955] 
2023-11-29 15:30:23.697117: Epoch time: 80.1 s 
2023-11-29 15:30:24.884024:  
2023-11-29 15:30:24.890024: Epoch 56 
2023-11-29 15:30:24.895029: Current learning rate: 0.00949 
2023-11-29 15:31:43.986050: train_loss -0.9501 
2023-11-29 15:31:43.996051: val_loss -0.935 
2023-11-29 15:31:44.015052: Pseudo dice [0.9826, 0.9829, 0.9552] 
2023-11-29 15:31:44.024052: Epoch time: 79.1 s 
2023-11-29 15:31:45.082144:  
2023-11-29 15:31:45.089144: Epoch 57 
2023-11-29 15:31:45.093496: Current learning rate: 0.00949 
2023-11-29 15:33:04.703201: train_loss -0.9496 
2023-11-29 15:33:04.711200: val_loss -0.9359 
2023-11-29 15:33:04.720199: Pseudo dice [0.9821, 0.9835, 0.9566] 
2023-11-29 15:33:04.727200: Epoch time: 79.62 s 
2023-11-29 15:33:04.736199: Yayy! New best EMA pseudo Dice: 0.9736 
2023-11-29 15:33:06.085752:  
2023-11-29 15:33:06.090750: Epoch 58 
2023-11-29 15:33:06.095748: Current learning rate: 0.00948 
2023-11-29 15:34:26.983299: train_loss -0.9502 
2023-11-29 15:34:26.988803: val_loss -0.9356 
2023-11-29 15:34:26.994813: Pseudo dice [0.9822, 0.983, 0.956] 
2023-11-29 15:34:27.002323: Epoch time: 80.9 s 
2023-11-29 15:34:27.008826: Yayy! New best EMA pseudo Dice: 0.9736 
2023-11-29 15:34:28.363330:  
2023-11-29 15:34:28.368906: Epoch 59 
2023-11-29 15:34:28.373297: Current learning rate: 0.00947 
2023-11-29 15:35:48.481430: train_loss -0.951 
2023-11-29 15:35:48.489945: val_loss -0.9361 
2023-11-29 15:35:48.495942: Pseudo dice [0.9822, 0.9833, 0.9564] 
2023-11-29 15:35:48.502461: Epoch time: 80.12 s 
2023-11-29 15:35:48.509975: Yayy! New best EMA pseudo Dice: 0.9736 
2023-11-29 15:35:49.879283:  
2023-11-29 15:35:49.884327: Epoch 60 
2023-11-29 15:35:49.889926: Current learning rate: 0.00946 
2023-11-29 15:37:10.776000: train_loss -0.9498 
2023-11-29 15:37:10.783513: val_loss -0.9321 
2023-11-29 15:37:10.790032: Pseudo dice [0.982, 0.9825, 0.9542] 
2023-11-29 15:37:10.795542: Epoch time: 80.9 s 
2023-11-29 15:37:11.997467:  
2023-11-29 15:37:12.002641: Epoch 61 
2023-11-29 15:37:12.007648: Current learning rate: 0.00945 
2023-11-29 15:38:30.536102: train_loss -0.9502 
2023-11-29 15:38:30.544614: val_loss -0.9357 
2023-11-29 15:38:30.552131: Pseudo dice [0.982, 0.9824, 0.9553] 
2023-11-29 15:38:30.559644: Epoch time: 78.54 s 
2023-11-29 15:38:31.643918:  
2023-11-29 15:38:31.649418: Epoch 62 
2023-11-29 15:38:31.654453: Current learning rate: 0.00944 
2023-11-29 15:39:52.366519: train_loss -0.9494 
2023-11-29 15:39:52.373524: val_loss -0.9345 
2023-11-29 15:39:52.381045: Pseudo dice [0.9823, 0.9823, 0.9546] 
2023-11-29 15:39:52.386557: Epoch time: 80.72 s 
2023-11-29 15:39:53.461937:  
2023-11-29 15:39:53.467442: Epoch 63 
2023-11-29 15:39:53.472785: Current learning rate: 0.00943 
2023-11-29 15:41:13.633919: train_loss -0.95 
2023-11-29 15:41:13.642431: val_loss -0.9341 
2023-11-29 15:41:13.648946: Pseudo dice [0.9823, 0.983, 0.9548] 
2023-11-29 15:41:13.655452: Epoch time: 80.17 s 
2023-11-29 15:41:14.748884:  
2023-11-29 15:41:14.753884: Epoch 64 
2023-11-29 15:41:14.758392: Current learning rate: 0.00942 
2023-11-29 15:42:33.206872: train_loss -0.9514 
2023-11-29 15:42:33.212872: val_loss -0.9366 
2023-11-29 15:42:33.220385: Pseudo dice [0.9824, 0.9835, 0.9563] 
2023-11-29 15:42:33.225903: Epoch time: 78.46 s 
2023-11-29 15:42:34.322803:  
2023-11-29 15:42:34.329399: Epoch 65 
2023-11-29 15:42:34.334965: Current learning rate: 0.00941 
2023-11-29 15:43:51.966267: train_loss -0.9516 
2023-11-29 15:43:51.974268: val_loss -0.9363 
2023-11-29 15:43:51.981266: Pseudo dice [0.9824, 0.9831, 0.9564] 
2023-11-29 15:43:51.988268: Epoch time: 77.65 s 
2023-11-29 15:43:53.073633:  
2023-11-29 15:43:53.078812: Epoch 66 
2023-11-29 15:43:53.083849: Current learning rate: 0.0094 
2023-11-29 15:45:13.714481: train_loss -0.952 
2023-11-29 15:45:13.721496: val_loss -0.9343 
2023-11-29 15:45:13.727702: Pseudo dice [0.9818, 0.9829, 0.9551] 
2023-11-29 15:45:13.734308: Epoch time: 80.64 s 
2023-11-29 15:45:14.949633:  
2023-11-29 15:45:14.955066: Epoch 67 
2023-11-29 15:45:14.960115: Current learning rate: 0.00939 
2023-11-29 15:46:33.747311: train_loss -0.952 
2023-11-29 15:46:33.755825: val_loss -0.9351 
2023-11-29 15:46:33.765057: Pseudo dice [0.9826, 0.983, 0.9549] 
2023-11-29 15:46:33.773062: Epoch time: 78.8 s 
2023-11-29 15:46:34.987938:  
2023-11-29 15:46:34.994452: Epoch 68 
2023-11-29 15:46:35.001462: Current learning rate: 0.00939 
2023-11-29 15:47:59.159517: train_loss -0.9516 
2023-11-29 15:47:59.167027: val_loss -0.9363 
2023-11-29 15:47:59.173531: Pseudo dice [0.9818, 0.9836, 0.9563] 
2023-11-29 15:47:59.181541: Epoch time: 84.17 s 
2023-11-29 15:48:00.296322:  
2023-11-29 15:48:00.302393: Epoch 69 
2023-11-29 15:48:00.306905: Current learning rate: 0.00938 
2023-11-29 15:49:21.531770: train_loss -0.9525 
2023-11-29 15:49:21.538280: val_loss -0.9329 
2023-11-29 15:49:21.546297: Pseudo dice [0.9822, 0.9823, 0.955] 
2023-11-29 15:49:21.552298: Epoch time: 81.24 s 
2023-11-29 15:49:22.668464:  
2023-11-29 15:49:22.673969: Epoch 70 
2023-11-29 15:49:22.679344: Current learning rate: 0.00937 
2023-11-29 15:50:40.432837: train_loss -0.9533 
2023-11-29 15:50:40.440837: val_loss -0.9352 
2023-11-29 15:50:40.447837: Pseudo dice [0.9821, 0.9834, 0.9561] 
2023-11-29 15:50:40.452837: Epoch time: 77.77 s 
2023-11-29 15:50:41.564233:  
2023-11-29 15:50:41.569268: Epoch 71 
2023-11-29 15:50:41.574561: Current learning rate: 0.00936 
2023-11-29 15:52:01.814654: train_loss -0.9528 
2023-11-29 15:52:01.822654: val_loss -0.936 
2023-11-29 15:52:01.829656: Pseudo dice [0.9819, 0.9836, 0.9563] 
2023-11-29 15:52:01.836656: Epoch time: 80.25 s 
2023-11-29 15:52:03.065042:  
2023-11-29 15:52:03.069983: Epoch 72 
2023-11-29 15:52:03.075021: Current learning rate: 0.00935 
2023-11-29 15:53:21.758877: train_loss -0.9536 
2023-11-29 15:53:21.766878: val_loss -0.9352 
2023-11-29 15:53:21.772882: Pseudo dice [0.9818, 0.9835, 0.9555] 
2023-11-29 15:53:21.779877: Epoch time: 78.69 s 
2023-11-29 15:53:22.890365:  
2023-11-29 15:53:22.896443: Epoch 73 
2023-11-29 15:53:22.900444: Current learning rate: 0.00934 
2023-11-29 15:54:41.710495: train_loss -0.9541 
2023-11-29 15:54:41.718496: val_loss -0.9353 
2023-11-29 15:54:41.724494: Pseudo dice [0.9818, 0.9835, 0.9564] 
2023-11-29 15:54:41.730494: Epoch time: 78.82 s 
2023-11-29 15:54:41.735496: Yayy! New best EMA pseudo Dice: 0.9736 
2023-11-29 15:54:43.150647:  
2023-11-29 15:54:43.155648: Epoch 74 
2023-11-29 15:54:43.161649: Current learning rate: 0.00933 
2023-11-29 15:56:01.616941: train_loss -0.9536 
2023-11-29 15:56:01.624942: val_loss -0.9374 
2023-11-29 15:56:01.630943: Pseudo dice [0.9825, 0.9835, 0.956] 
2023-11-29 15:56:01.637940: Epoch time: 78.47 s 
2023-11-29 15:56:01.644941: Yayy! New best EMA pseudo Dice: 0.9737 
2023-11-29 15:56:03.031939:  
2023-11-29 15:56:03.037115: Epoch 75 
2023-11-29 15:56:03.042115: Current learning rate: 0.00932 
2023-11-29 15:57:23.518703: train_loss -0.9541 
2023-11-29 15:57:23.527700: val_loss -0.9309 
2023-11-29 15:57:23.536700: Pseudo dice [0.9818, 0.9824, 0.9534] 
2023-11-29 15:57:23.545704: Epoch time: 80.49 s 
2023-11-29 15:57:24.827777:  
2023-11-29 15:57:24.832775: Epoch 76 
2023-11-29 15:57:24.839774: Current learning rate: 0.00931 
2023-11-29 15:58:44.028368: train_loss -0.954 
2023-11-29 15:58:44.034372: val_loss -0.9336 
2023-11-29 15:58:44.042375: Pseudo dice [0.9821, 0.9828, 0.9544] 
2023-11-29 15:58:44.047883: Epoch time: 79.2 s 
2023-11-29 15:58:45.282530:  
2023-11-29 15:58:45.288779: Epoch 77 
2023-11-29 15:58:45.293784: Current learning rate: 0.0093 
2023-11-29 16:00:03.961055: train_loss -0.9535 
2023-11-29 16:00:03.971572: val_loss -0.9363 
2023-11-29 16:00:03.978578: Pseudo dice [0.982, 0.9841, 0.9566] 
2023-11-29 16:00:03.986747: Epoch time: 78.68 s 
2023-11-29 16:00:05.126093:  
2023-11-29 16:00:05.131469: Epoch 78 
2023-11-29 16:00:05.136477: Current learning rate: 0.0093 
2023-11-29 16:01:25.251439: train_loss -0.9546 
2023-11-29 16:01:25.258439: val_loss -0.9316 
2023-11-29 16:01:25.265438: Pseudo dice [0.9823, 0.9826, 0.9545] 
2023-11-29 16:01:25.271438: Epoch time: 80.13 s 
2023-11-29 16:01:26.418447:  
2023-11-29 16:01:26.423134: Epoch 79 
2023-11-29 16:01:26.428473: Current learning rate: 0.00929 
2023-11-29 16:02:47.537885: train_loss -0.9542 
2023-11-29 16:02:47.544884: val_loss -0.9337 
2023-11-29 16:02:47.550882: Pseudo dice [0.982, 0.9834, 0.956] 
2023-11-29 16:02:47.556885: Epoch time: 81.12 s 
2023-11-29 16:02:48.702612:  
2023-11-29 16:02:48.707618: Epoch 80 
2023-11-29 16:02:48.712657: Current learning rate: 0.00928 
2023-11-29 16:04:06.139707: train_loss -0.9552 
2023-11-29 16:04:06.147705: val_loss -0.9326 
2023-11-29 16:04:06.156706: Pseudo dice [0.9822, 0.9826, 0.955] 
2023-11-29 16:04:06.162709: Epoch time: 77.44 s 
2023-11-29 16:04:07.302554:  
2023-11-29 16:04:07.307598: Epoch 81 
2023-11-29 16:04:07.311602: Current learning rate: 0.00927 
2023-11-29 16:05:29.055146: train_loss -0.9549 
2023-11-29 16:05:29.062146: val_loss -0.9333 
2023-11-29 16:05:29.069148: Pseudo dice [0.9816, 0.9834, 0.9556] 
2023-11-29 16:05:29.075271: Epoch time: 81.75 s 
2023-11-29 16:05:30.330883:  
2023-11-29 16:05:30.336584: Epoch 82 
2023-11-29 16:05:30.341590: Current learning rate: 0.00926 
2023-11-29 16:06:50.417013: train_loss -0.9551 
2023-11-29 16:06:50.425014: val_loss -0.9316 
2023-11-29 16:06:50.432023: Pseudo dice [0.982, 0.9828, 0.955] 
2023-11-29 16:06:50.440014: Epoch time: 80.09 s 
2023-11-29 16:06:51.493742:  
2023-11-29 16:06:51.499948: Epoch 83 
2023-11-29 16:06:51.503785: Current learning rate: 0.00925 
2023-11-29 16:08:09.235110: train_loss -0.9567 
2023-11-29 16:08:09.242109: val_loss -0.9345 
2023-11-29 16:08:09.249593: Pseudo dice [0.9817, 0.9837, 0.9564] 
2023-11-29 16:08:09.255595: Epoch time: 77.74 s 
2023-11-29 16:08:10.311287:  
2023-11-29 16:08:10.316291: Epoch 84 
2023-11-29 16:08:10.321796: Current learning rate: 0.00924 
2023-11-29 16:09:28.537192: train_loss -0.9564 
2023-11-29 16:09:28.544195: val_loss -0.9304 
2023-11-29 16:09:28.551192: Pseudo dice [0.9823, 0.9828, 0.9551] 
2023-11-29 16:09:28.558193: Epoch time: 78.23 s 
2023-11-29 16:09:29.607741:  
2023-11-29 16:09:29.613487: Epoch 85 
2023-11-29 16:09:29.617530: Current learning rate: 0.00923 
2023-11-29 16:10:48.761619: train_loss -0.9562 
2023-11-29 16:10:48.769618: val_loss -0.9311 
2023-11-29 16:10:48.775618: Pseudo dice [0.9818, 0.9827, 0.9553] 
2023-11-29 16:10:48.782621: Epoch time: 79.15 s 
2023-11-29 16:10:49.850915:  
2023-11-29 16:10:49.856875: Epoch 86 
2023-11-29 16:10:49.862878: Current learning rate: 0.00922 
2023-11-29 16:12:09.597241: train_loss -0.9565 
2023-11-29 16:12:09.603747: val_loss -0.9349 
2023-11-29 16:12:09.610752: Pseudo dice [0.982, 0.9831, 0.9567] 
2023-11-29 16:12:09.618752: Epoch time: 79.75 s 
2023-11-29 16:12:10.672564:  
2023-11-29 16:12:10.677567: Epoch 87 
2023-11-29 16:12:10.682558: Current learning rate: 0.00921 
2023-11-29 16:13:29.705579: train_loss -0.9561 
2023-11-29 16:13:29.715580: val_loss -0.9314 
2023-11-29 16:13:29.723578: Pseudo dice [0.9819, 0.9826, 0.9546] 
2023-11-29 16:13:29.730578: Epoch time: 79.03 s 
2023-11-29 16:13:30.943380:  
2023-11-29 16:13:30.948384: Epoch 88 
2023-11-29 16:13:30.953383: Current learning rate: 0.0092 
2023-11-29 16:14:48.503349: train_loss -0.9565 
2023-11-29 16:14:48.512356: val_loss -0.9287 
2023-11-29 16:14:48.521359: Pseudo dice [0.9817, 0.9826, 0.9551] 
2023-11-29 16:14:48.530356: Epoch time: 77.56 s 
2023-11-29 16:14:49.766363:  
2023-11-29 16:14:49.772419: Epoch 89 
2023-11-29 16:14:49.777404: Current learning rate: 0.0092 
2023-11-29 16:16:09.438251: train_loss -0.9571 
2023-11-29 16:16:09.445254: val_loss -0.9324 
2023-11-29 16:16:09.452251: Pseudo dice [0.9827, 0.9826, 0.9552] 
2023-11-29 16:16:09.458254: Epoch time: 79.67 s 
2023-11-29 16:16:10.514121:  
2023-11-29 16:16:10.519120: Epoch 90 
2023-11-29 16:16:10.525130: Current learning rate: 0.00919 
2023-11-29 16:17:29.883827: train_loss -0.9564 
2023-11-29 16:17:29.891829: val_loss -0.9308 
2023-11-29 16:17:29.898827: Pseudo dice [0.9821, 0.983, 0.955] 
2023-11-29 16:17:29.905827: Epoch time: 79.37 s 
2023-11-29 16:17:30.959817:  
2023-11-29 16:17:30.965822: Epoch 91 
2023-11-29 16:17:30.970822: Current learning rate: 0.00918 
2023-11-29 16:18:49.043084: train_loss -0.9565 
2023-11-29 16:18:49.051084: val_loss -0.9307 
2023-11-29 16:18:49.058083: Pseudo dice [0.9819, 0.9821, 0.9546] 
2023-11-29 16:18:49.066087: Epoch time: 78.08 s 
2023-11-29 16:18:50.108571:  
2023-11-29 16:18:50.114030: Epoch 92 
2023-11-29 16:18:50.118028: Current learning rate: 0.00917 
2023-11-29 16:20:10.246202: train_loss -0.9573 
2023-11-29 16:20:10.254205: val_loss -0.9298 
2023-11-29 16:20:10.261202: Pseudo dice [0.9815, 0.9831, 0.9555] 
2023-11-29 16:20:10.269201: Epoch time: 80.14 s 
2023-11-29 16:20:11.431602:  
2023-11-29 16:20:11.437564: Epoch 93 
2023-11-29 16:20:11.443289: Current learning rate: 0.00916 
2023-11-29 16:21:29.764727: train_loss -0.9579 
2023-11-29 16:21:29.771724: val_loss -0.9311 
2023-11-29 16:21:29.780121: Pseudo dice [0.9822, 0.9826, 0.9549] 
2023-11-29 16:21:29.787661: Epoch time: 78.33 s 
2023-11-29 16:21:30.828654:  
2023-11-29 16:21:30.833656: Epoch 94 
2023-11-29 16:21:30.838841: Current learning rate: 0.00915 
2023-11-29 16:22:51.059594: train_loss -0.9583 
2023-11-29 16:22:51.066593: val_loss -0.9321 
2023-11-29 16:22:51.073109: Pseudo dice [0.9824, 0.983, 0.9554] 
2023-11-29 16:22:51.080622: Epoch time: 80.23 s 
2023-11-29 16:22:52.125095:  
2023-11-29 16:22:52.131728: Epoch 95 
2023-11-29 16:22:52.136777: Current learning rate: 0.00914 
2023-11-29 16:24:12.526644: train_loss -0.9579 
2023-11-29 16:24:12.535649: val_loss -0.9291 
2023-11-29 16:24:12.541651: Pseudo dice [0.9819, 0.9824, 0.954] 
2023-11-29 16:24:12.548160: Epoch time: 80.4 s 
2023-11-29 16:24:13.589270:  
2023-11-29 16:24:13.594311: Epoch 96 
2023-11-29 16:24:13.599270: Current learning rate: 0.00913 
2023-11-29 16:25:31.621446: train_loss -0.9579 
2023-11-29 16:25:31.629446: val_loss -0.9326 
2023-11-29 16:25:31.636446: Pseudo dice [0.982, 0.9833, 0.9561] 
2023-11-29 16:25:31.643447: Epoch time: 78.03 s 
2023-11-29 16:25:32.727502:  
2023-11-29 16:25:32.733504: Epoch 97 
2023-11-29 16:25:32.738503: Current learning rate: 0.00912 
2023-11-29 16:26:56.113994: train_loss -0.9578 
2023-11-29 16:26:56.122508: val_loss -0.9299 
2023-11-29 16:26:56.128507: Pseudo dice [0.982, 0.9829, 0.9547] 
2023-11-29 16:26:56.136019: Epoch time: 83.39 s 
2023-11-29 16:26:57.278746:  
2023-11-29 16:26:57.285257: Epoch 98 
2023-11-29 16:26:57.290255: Current learning rate: 0.00911 
2023-11-29 16:28:18.702553: train_loss -0.9581 
2023-11-29 16:28:18.710056: val_loss -0.9304 
2023-11-29 16:28:18.717456: Pseudo dice [0.9825, 0.9825, 0.9546] 
2023-11-29 16:28:18.725012: Epoch time: 81.42 s 
2023-11-29 16:28:19.946826:  
2023-11-29 16:28:19.952389: Epoch 99 
2023-11-29 16:28:19.957433: Current learning rate: 0.0091 
2023-11-29 16:29:41.329383: train_loss -0.9585 
2023-11-29 16:29:41.337388: val_loss -0.9295 
2023-11-29 16:29:41.345910: Pseudo dice [0.9822, 0.9831, 0.9551] 
2023-11-29 16:29:41.353421: Epoch time: 81.38 s 
2023-11-29 16:29:42.753497:  
2023-11-29 16:29:42.758501: Epoch 100 
2023-11-29 16:29:42.764647: Current learning rate: 0.0091 
2023-11-29 16:31:03.200483: train_loss -0.9585 
2023-11-29 16:31:03.208482: val_loss -0.9324 
2023-11-29 16:31:03.215999: Pseudo dice [0.9819, 0.9837, 0.9567] 
2023-11-29 16:31:03.222515: Epoch time: 80.45 s 
2023-11-29 16:31:04.370257:  
2023-11-29 16:31:04.376258: Epoch 101 
2023-11-29 16:31:04.382492: Current learning rate: 0.00909 
2023-11-29 16:32:27.495061: train_loss -0.9592 
2023-11-29 16:32:27.504313: val_loss -0.9293 
2023-11-29 16:32:27.513294: Pseudo dice [0.9818, 0.9829, 0.9549] 
2023-11-29 16:32:27.522816: Epoch time: 83.13 s 
2023-11-29 16:32:28.646325:  
2023-11-29 16:32:28.652524: Epoch 102 
2023-11-29 16:32:28.657287: Current learning rate: 0.00908 
2023-11-29 16:33:50.544655: train_loss -0.9594 
2023-11-29 16:33:50.545656: val_loss -0.9294 
2023-11-29 16:33:50.556173: Pseudo dice [0.9822, 0.9829, 0.955] 
2023-11-29 16:33:50.568689: Epoch time: 81.9 s 
2023-11-29 16:33:51.853724:  
2023-11-29 16:33:51.854725: Epoch 103 
2023-11-29 16:33:51.859902: Current learning rate: 0.00907 
2023-11-29 16:35:11.644000: train_loss -0.9582 
2023-11-29 16:35:11.645000: val_loss -0.9286 
2023-11-29 16:35:11.653510: Pseudo dice [0.9826, 0.9824, 0.9545] 
2023-11-29 16:35:11.660017: Epoch time: 79.79 s 
2023-11-29 16:35:12.737185:  
2023-11-29 16:35:12.737185: Epoch 104 
2023-11-29 16:35:12.742695: Current learning rate: 0.00906 
2023-11-29 16:36:35.332906: train_loss -0.9588 
2023-11-29 16:36:35.332906: val_loss -0.9286 
2023-11-29 16:36:35.341419: Pseudo dice [0.9819, 0.9831, 0.9549] 
2023-11-29 16:36:35.348933: Epoch time: 82.6 s 
2023-11-29 16:36:36.554559:  
2023-11-29 16:36:36.555560: Epoch 105 
2023-11-29 16:36:36.561442: Current learning rate: 0.00905 
2023-11-29 16:39:11.389671: train_loss -0.959 
2023-11-29 16:39:11.392182: val_loss -0.9267 
2023-11-29 16:39:11.400695: Pseudo dice [0.9822, 0.9827, 0.9544] 
2023-11-29 16:39:11.409206: Epoch time: 154.84 s 
2023-11-29 16:39:12.543073:  
2023-11-29 16:39:12.544072: Epoch 106 
2023-11-29 16:39:12.549583: Current learning rate: 0.00904 
2023-11-29 16:40:40.625821: train_loss -0.9595 
2023-11-29 16:40:40.626818: val_loss -0.9263 
2023-11-29 16:40:40.638864: Pseudo dice [0.9816, 0.9824, 0.9542] 
2023-11-29 16:40:40.649388: Epoch time: 88.08 s 
2023-11-29 16:40:41.826523:  
2023-11-29 16:40:41.827523: Epoch 107 
2023-11-29 16:40:41.832767: Current learning rate: 0.00903 
2023-11-29 16:42:04.805153: train_loss -0.9596 
2023-11-29 16:42:04.806154: val_loss -0.9284 
2023-11-29 16:42:04.815153: Pseudo dice [0.9816, 0.9829, 0.9552] 
2023-11-29 16:42:04.822152: Epoch time: 82.98 s 
2023-11-29 16:42:06.031007:  
2023-11-29 16:42:06.031007: Epoch 108 
2023-11-29 16:42:06.037005: Current learning rate: 0.00902 
2023-11-29 16:43:25.978279: train_loss -0.9595 
2023-11-29 16:43:25.979280: val_loss -0.9261 
2023-11-29 16:43:25.986281: Pseudo dice [0.9816, 0.9826, 0.9536] 
2023-11-29 16:43:25.994281: Epoch time: 79.95 s 
2023-11-29 16:43:27.112019:  
2023-11-29 16:43:27.113019: Epoch 109 
2023-11-29 16:43:27.118023: Current learning rate: 0.00901 
2023-11-29 16:44:44.469289: train_loss -0.96 
2023-11-29 16:44:44.469289: val_loss -0.9295 
2023-11-29 16:44:44.477290: Pseudo dice [0.9819, 0.9835, 0.9558] 
2023-11-29 16:44:44.484290: Epoch time: 77.36 s 
2023-11-29 16:44:45.665329:  
2023-11-29 16:44:45.665877: Epoch 110 
2023-11-29 16:44:45.671278: Current learning rate: 0.009 
2023-11-29 16:46:03.034445: train_loss -0.9599 
2023-11-29 16:46:03.034445: val_loss -0.9311 
2023-11-29 16:46:03.043446: Pseudo dice [0.982, 0.9832, 0.9559] 
2023-11-29 16:46:03.051445: Epoch time: 77.37 s 
2023-11-29 16:46:04.124780:  
2023-11-29 16:46:04.125787: Epoch 111 
2023-11-29 16:46:04.131809: Current learning rate: 0.009 
2023-11-29 16:47:24.004306: train_loss -0.9595 
2023-11-29 16:47:24.011860: val_loss -0.9275 
2023-11-29 16:47:24.019857: Pseudo dice [0.9822, 0.9825, 0.9543] 
2023-11-29 16:47:24.030858: Epoch time: 79.88 s 
2023-11-29 16:47:25.066186:  
2023-11-29 16:47:25.067419: Epoch 112 
2023-11-29 16:47:25.073568: Current learning rate: 0.00899 
2023-11-29 16:48:39.900782: train_loss -0.9589 
2023-11-29 16:48:39.901780: val_loss -0.9312 
2023-11-29 16:48:39.909780: Pseudo dice [0.9823, 0.9834, 0.9555] 
2023-11-29 16:48:39.917779: Epoch time: 74.84 s 
2023-11-29 16:48:40.960821:  
2023-11-29 16:48:40.961768: Epoch 113 
2023-11-29 16:48:40.968307: Current learning rate: 0.00898 
2023-11-29 16:49:58.052867: train_loss -0.9591 
2023-11-29 16:49:58.052867: val_loss -0.932 
2023-11-29 16:49:58.061868: Pseudo dice [0.9825, 0.9835, 0.9566] 
2023-11-29 16:49:58.068099: Epoch time: 77.09 s 
2023-11-29 16:49:59.149450:  
2023-11-29 16:49:59.149450: Epoch 114 
2023-11-29 16:49:59.156452: Current learning rate: 0.00897 
2023-11-29 16:51:17.597380: train_loss -0.9604 
2023-11-29 16:51:17.598380: val_loss -0.9282 
2023-11-29 16:51:17.608382: Pseudo dice [0.9823, 0.9832, 0.955] 
2023-11-29 16:51:17.616381: Epoch time: 78.45 s 
2023-11-29 16:51:18.798555:  
2023-11-29 16:51:18.798555: Epoch 115 
2023-11-29 16:51:18.805612: Current learning rate: 0.00896 
2023-11-29 16:52:37.810278: train_loss -0.9605 
2023-11-29 16:52:37.810278: val_loss -0.9267 
2023-11-29 16:52:37.824788: Pseudo dice [0.9815, 0.9828, 0.9547] 
2023-11-29 16:52:37.838789: Epoch time: 79.01 s 
2023-11-29 16:52:38.943690:  
2023-11-29 16:52:38.943690: Epoch 116 
2023-11-29 16:52:38.950984: Current learning rate: 0.00895 
2023-11-29 16:53:56.908134: train_loss -0.9606 
2023-11-29 16:53:56.908134: val_loss -0.9292 
2023-11-29 16:53:56.916136: Pseudo dice [0.9817, 0.983, 0.9553] 
2023-11-29 16:53:56.927136: Epoch time: 77.97 s 
2023-11-29 16:53:58.019735:  
2023-11-29 16:53:58.020734: Epoch 117 
2023-11-29 16:53:58.027733: Current learning rate: 0.00894 
2023-11-29 16:55:15.852731: train_loss -0.9589 
2023-11-29 16:55:15.852731: val_loss -0.9272 
2023-11-29 16:55:15.861732: Pseudo dice [0.9819, 0.9823, 0.954] 
2023-11-29 16:55:15.870737: Epoch time: 77.83 s 
2023-11-29 16:55:16.960499:  
2023-11-29 16:55:16.961498: Epoch 118 
2023-11-29 16:55:16.967992: Current learning rate: 0.00893 
2023-11-29 16:56:35.006607: train_loss -0.96 
2023-11-29 16:56:35.006607: val_loss -0.9281 
2023-11-29 16:56:35.017608: Pseudo dice [0.9819, 0.9829, 0.9555] 
2023-11-29 16:56:35.026607: Epoch time: 78.05 s 
2023-11-29 16:56:36.118452:  
2023-11-29 16:56:36.119449: Epoch 119 
2023-11-29 16:56:36.125452: Current learning rate: 0.00892 
2023-11-29 16:57:55.060152: train_loss -0.9607 
2023-11-29 16:57:55.061153: val_loss -0.927 
2023-11-29 16:57:55.071152: Pseudo dice [0.9824, 0.9828, 0.9548] 
2023-11-29 16:57:55.082152: Epoch time: 78.94 s 
2023-11-29 16:57:56.231363:  
2023-11-29 16:57:56.231363: Epoch 120 
2023-11-29 16:57:56.238364: Current learning rate: 0.00891 
